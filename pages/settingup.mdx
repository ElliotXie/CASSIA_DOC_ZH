# Setup and Installation

## Installing Required Packages

First, ensure you have the `reticulate` package and the `devtools` package installed.

```R
install.packages("reticulate")
install.packages("devtools")
```

Next, you'll need to install the CASSIA package. You can install it directly:

```R
# Install the CASSIA package
library(devtools)
devtools::install_github("ElliotXie/CASSIA/CASSIA_R")
```

## Setting Up the Python Environment

CASSIA relies on Python for some of its backend processing. When you load the CASSIA package, it attempts to set up the required Python environment automatically. However, if you encounter issues, you can use the `setup_cassia_env()` function to create and configure the necessary Python environment manually.

```R
library(CASSIA)

# Manually set up the Python environment if needed
setup_cassia_env(conda_env = "cassia_env")
```

This function will:

- Create a new Conda environment named `cassia_env` if it doesn't already exist.
- Install the required Python packages: `openai`, `pandas`, `numpy`, `scikit-learn`, `requests`, and `anthropic`.

## Setting API Keys


To use LLMs like OpenAI's GPT-4, Anthropic's Claude, or models via OpenRouter, you need to set your API keys using the `setLLMApiKey()` function. 

**Note: You must set at least one API key to use CASSIA.**

```R
# For OpenAI
setLLMApiKey("your_openai_api_key", provider = "openai", persist = TRUE)

# For Anthropic
setLLMApiKey("your_anthropic_api_key", provider = "anthropic", persist = TRUE)

# For OpenRouter
setLLMApiKey("your_openrouter_api_key", provider = "openrouter", persist = TRUE)
```

- Replace `"your_api_key"` with your actual API key.
- Set `provider` to `"openai"`, `"anthropic"`, or `"openrouter"` depending on your provider.
- Setting `persist = TRUE` saves the key in your `.Renviron` file for future sessions.



## How to Select Models and Providers

There are three providers to choose from: `openai`, `anthropic`, and `openrouter`. Each provider has its own models and pricing.
Note that the model name must be set exactly as shown below or the model will not be found.

### OpenAI

OpenAI has three most recommended models to choose from:

- `gpt-4o`
- `gpt-4o-mini`
- `o1-mini`

`gpt-4o` is the most balanced and recommended model. `gpt-4o-mini` is a cheaper and faster version of `gpt-4o`. `o1-mini` is the more powerful version enabling more complex reasoning but at a higher cost, which is not recommended in the default setting.

### Anthropic

Anthropic has one recommended model: This is the powerful model with the best performance.

- `claude-3-5-sonnet-20241022`

### OpenRouter

OpenRouter is a platform that offers access to almost all the models supported by major providers. It is actually recommended to use OpenRouter to access claude-3-5-sonnet since it has the highest rate limit. And we can also use it to access a number of open source models such as llama-3.2 and deepseek2. These open source models are much cheaper with a slight performance decrease.

- `anthropic/claude-3.5-sonnet`
- `openai/gpt-4o-2024-11-20`
- `meta-llama/llama-3.2-90b-vision-instruct` 
